# ğŸ¤– Funny Tales Chatbot

**AI-powered funny storytelling chatbot** built as part of the *Es Magico AI Studio* assignment.
It answers user questions about classic stories in a humorous tone, and even generates related images â€” all **offline-capable** and **lightweight**.

---
[![Watch the demo](https://img.shields.io/badge/ğŸŒŒ-Watch%20Demo-red)](https://vimeo.com/1130448114?fl=ip&fe=ec)

## ğŸ§  Overview

**Project Goal:**
Create a **Funny Story Chatbot** trained on three public-domain classics:

* *Alice in Wonderland*
* *Arabian Nights*
* *Gulliverâ€™s Travels*

The chatbot can:

* Answer questions about these stories with a **funny, story-like tone**
* **Generate related images**
* Handle unrelated queries gracefully
* Run entirely **offline on CPU**

---

## âš™ï¸ Architecture

```
User Query
   â†“
Semantic Search (FAISS)
   â†“
Context Retrieved
   â†“
TinyLlama (Text Generation)
   â†“
Funny Story Reply
   â†“
Stable Diffusion Turbo (Image Generation)
   â†“
Flask Web Interface Output
```

---

## ğŸ§© Tech Stack

| Component           | Technology                             |                                                
| ------------------- | -------------------------------------- | 
| **Backend**         | Flask                                  |
| **Embedding Model** | sentence-transformers/all-MiniLM-L6-v2 | 
| **Text Model**      | TinyLlama-1.1B-Chat-v1.0               | 
| **Image Model**     | stabilityai/sd-turbo                   | 
| **Vector Store**    | FAISS                                  | 
| **PDF Extraction**  | pdfplumber + regex                     | 
| **Frontend**        | Flask + Jinja2 + CSS                   | 

---


## ğŸ§  RAG for Retrieval & Generation

**Retrieval:**

* User query â†’ embedding â†’ top 4 chunks via FAISS
* If similarity < 0.45 â†’ returns funny fallback:

> "I don't know that, my curious traveler! My brain is on vacationâ€¦"

**Generation:**

* Retrieved context + prompt template â†’ TinyLlama response
* Output includes:

  * `reply_text` (funny answer)
  * `image_prompt` (for image generation)

---

## ğŸ¨ Image Generation

* Uses **Stable Diffusion Turbo (sd-turbo)** via `diffusers`
* Saves generated images under `static/generated_*.png`

---

## ğŸ§° Project Structure

```
project_root/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ backend.py
â”‚   â”œâ”€â”€ utils.py
â”‚   â”œâ”€â”€ logger.py
â”‚   â”œâ”€â”€ model_saving.py
    â”œâ”€â”€ test_index.py
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ stories_pdf/
â”‚   â”œâ”€â”€ index.faiss
â”‚   â”œâ”€â”€ meta.pkl
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ all-MiniLM-L6-v2_local/
â”‚   â”œâ”€â”€ TinyLlama-1.1B-Chat-v1.0_local/
â”‚   â””â”€â”€ sd-turbo_local/
â”‚
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ style.css
â”‚   â””â”€â”€ generated_*.png
â”‚
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html
â”‚
â””â”€â”€ application.py
```

---

## ğŸ§® Local Model Setup

Models are stored locally for **offline inference**:

```
models/
â”œâ”€â”€ all-MiniLM-L6-v2_local/
â”œâ”€â”€ TinyLlama-1.1B-Chat-v1.0_local/
â””â”€â”€ sd-turbo_local/
```

Downloaded using:

```python
from huggingface_hub import snapshot_download
snapshot_download(repo_id="TinyLlama/TinyLlama-1.1B-Chat-v1.0", local_dir="models/TinyLlama-1.1B-Chat-v1.0_local")
```

âœ… Benefits:

* No runtime downloads
* Offline & CPU-friendly
* Faster startup


---

## ğŸš€ Future Enhancements

* ğŸ¤ Add **speech-to-text (Whisper)** & **text-to-speech (gTTS)**
* ğŸŒ **Multilingual** support (Hindi, Spanish)
* ğŸ’¬ **Session memory** for multi-turn chats
* â˜ï¸ **Docker + Render/HF Spaces** deployment

---

## ğŸ Conclusion

**Funny Tales Chatbot** demonstrates an end-to-end **Retrieval-Augmented Generation** system that runs entirely on open-source, offline tools.
It blends **semantic search, creative text generation, and AI-driven image synthesis** â€” built for fun, education, and storytelling.
